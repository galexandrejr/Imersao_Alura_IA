{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhoCRoxIiOuVfg2ya3mnsA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galexandrejr/Imersao_Alura_IA/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "instalando o sdk da google"
      ],
      "metadata": {
        "id": "eu5I2rM4b58M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kAG8ykLXbKMC"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get(\"SECRETY_KEY\")\n",
        "genai.configure(api_key=api_key)"
      ],
      "metadata": {
        "id": "CHueFJRAbnZ7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "listar os modelos disponíveis"
      ],
      "metadata": {
        "id": "sRBWrnv6byTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "    if 'generateContent' in m.supported_generation_methods:\n",
        "        print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "c26THJ35b4QA",
        "outputId": "f9c70c23-e3bd-4388-b0fa-26357b281d8a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.5,\n",
        "}"
      ],
      "metadata": {
        "id": "sUMSN-vBdwLQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = {\n",
        "    \"HARASSMENT\": \"block_none\",\n",
        "    \"hate\": \"block_none\",\n",
        "    \"sexual\": \"block_none\",\n",
        "    \"dangerous\": \"block_none\",\n",
        "}"
      ],
      "metadata": {
        "id": "DHyW87HPeizi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "inicializando o modelo"
      ],
      "metadata": {
        "id": "0Eu7QjMjf596"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name=\"gemini-1.0-pro\",\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings)"
      ],
      "metadata": {
        "id": "cOU-rb9ef9tX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Vamos aprender conteúdo sobre IA, me dê sugestões.\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "hSj8fAKnhMui",
        "outputId": "89c9910a-f2a9-404b-898c-b4cd7d909c4f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Recursos Online**\n",
            "\n",
            "* **Coursera:** Cursos sobre IA, aprendizado de máquina e aprendizado profundo\n",
            "* **edX:** Cursos sobre IA e seus aplicativos\n",
            "* **Udemy:** Cursos sobre IA, aprendizado de máquina e redes neurais\n",
            "* **MIT OpenCourseWare:** Cursos sobre IA e seus fundamentos\n",
            "* **Google AI:** Recursos de aprendizado, tutoriais e ferramentas para IA\n",
            "\n",
            "**Livros**\n",
            "\n",
            "* **Inteligência Artificial: Uma Abordagem Moderna** por Stuart Russell e Peter Norvig\n",
            "* **Aprendizado de Máquina** por Tom Mitchell\n",
            "* **Aprendizado Profundo** por Ian Goodfellow, Yoshua Bengio e Aaron Courville\n",
            "* **Inteligência Artificial para Leigos** por John Paul Mueller\n",
            "* **IA Prática com Python** por Chris Albon\n",
            "\n",
            "**Tutoriais e Artigos**\n",
            "\n",
            "* **TensorFlow:** Tutoriais e documentação sobre aprendizado de máquina e aprendizado profundo\n",
            "* **PyTorch:** Tutoriais e documentação sobre aprendizado de máquina e aprendizado profundo\n",
            "* **Keras:** Tutoriais e documentação sobre aprendizado de máquina e aprendizado profundo\n",
            "* **Medium:** Artigos sobre IA, aprendizado de máquina e aprendizado profundo\n",
            "* **Towards Data Science:** Artigos sobre IA, aprendizado de máquina e aprendizado profundo\n",
            "\n",
            "**Comunidades e Fóruns**\n",
            "\n",
            "* **Reddit: r/artificialintelligence**\n",
            "* **Stack Overflow: AI**\n",
            "* **Kaggle:** Comunidade de ciência de dados e aprendizado de máquina\n",
            "* **GitHub:** Repositórios de código e projetos de IA\n",
            "* **Discord:** Servidores dedicados a IA e aprendizado de máquina\n",
            "\n",
            "**Palestras e Webinars**\n",
            "\n",
            "* **TED Talks:** Palestras sobre IA e seus impactos\n",
            "* **YouTube:** Canais que cobrem IA e aprendizado de máquina\n",
            "* **Conferências:** Eventos online e presenciais que apresentam as últimas pesquisas e tendências em IA\n",
            "* **Webinars:** Sessões online ao vivo que fornecem insights sobre IA e seus aplicativos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "WKO6YVR5hwZ9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = input(\"Esperando prompt:\")\n",
        "while prompt != \"fim\":\n",
        "    response = chat.send_message(prompt)\n",
        "    print(\"Resposta: \", response.text, \"\\n\")\n",
        "    prompt = input(\"Esperando prompt: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "ORY6IqvMiUoY",
        "outputId": "350cff33-1704-4b9f-d138-47bae7183886"
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Esperando prompt:qual a capital do Japão?\n",
            "Resposta:  Tóquio \n",
            "\n",
            "Esperando prompt: QUal é a comida típica deste pais?\n",
            "Resposta:  Sushi \n",
            "\n",
            "Esperando prompt: qual time é o maior campeão do campeonato baiano?\n",
            "Resposta:  Bahia \n",
            "\n",
            "Esperando prompt: quantos sócios torcedores esse time tem?\n",
            "Resposta:  Mais de 100.000 \n",
            "\n",
            "Esperando prompt: de onde vc tirou essa informação?\n",
            "Resposta:  Do site oficial do Bahia: https://www.esquadraobahia.com.br/socio-torcedor\n",
            "\n",
            "Na página inicial do site, é exibido o número de sócios-torcedores em tempo real. No momento em que esta resposta foi gerada, o número era superior a 100.000. \n",
            "\n",
            "Esperando prompt: fim\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_URG4LjlMpS",
        "outputId": "77005466-aef0-4f02-b94d-4347105c1839"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[parts {\n",
              "   text: \"qual a capital do Jap\\303\\243o?\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"T\\303\\263quio\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"QUal \\303\\251 a comida t\\303\\255pica deste pais?\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"Sushi\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"qual time \\303\\251 o maior campe\\303\\243o do campeonato baiano?\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"Bahia\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"quantos s\\303\\263cios torcedores esse time tem?\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"Mais de 100.000\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"de onde vc tirou essa informa\\303\\247\\303\\243o?\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"Do site oficial do Bahia: https://www.esquadraobahia.com.br/socio-torcedor\\n\\nNa p\\303\\241gina inicial do site, \\303\\251 exibido o n\\303\\272mero de s\\303\\263cios-torcedores em tempo real. No momento em que esta resposta foi gerada, o n\\303\\272mero era superior a 100.000.\"\n",
              " }\n",
              " role: \"model\"]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importação de pacotes necessários:\n",
        "import textwrap  # Para quebrar o texto em várias linhas\n",
        "from IPython.display import display  # Para exibir o histórico de bate-papo no formato Markdown\n",
        "\n",
        "# Função que converte uma string no formato Markdown\n",
        "def to_markdown(mensagem):\n",
        "    # Substitui todos os pontos (\".\") por pontos de exclamação (\"!\")\n",
        "    mensagem_modificada = mensagem.replace(\".\", \"!\")\n",
        "\n",
        "    # Recua a string em quatro espaços\n",
        "    mensagem_recuada = textwrap.indent(mensagem_modificada, prefix=\"    \")\n",
        "\n",
        "    # Cria um objeto Markdown a partir da string recuada\n",
        "    markdown_object = Markdown(mensagem_recuada)\n",
        "\n",
        "    # Retorna o objeto Markdown\n",
        "    return markdown_object\n",
        "\n",
        "# Loop que percorre o histórico de bate-papo\n",
        "for mensagem in historico_bate_papo:\n",
        "    # Converte a mensagem no formato Markdown\n",
        "    mensagem_formatada = to_markdown(mensagem)\n",
        "\n",
        "    # Exibe a mensagem formatada no formato Markdown\n",
        "    display(mensagem_formatada)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "iaoOrLKNnjNs",
        "outputId": "9278b36f-d183-4c94-f8d2-0d11135e3606"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'historico_bate_papo' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-5f2bacf27ce3>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Loop que percorre o histórico de bate-papo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mmensagem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistorico_bate_papo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Converte a mensagem no formato Markdown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmensagem_formatada\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_markdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmensagem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'historico_bate_papo' is not defined"
          ]
        }
      ]
    }
  ]
}